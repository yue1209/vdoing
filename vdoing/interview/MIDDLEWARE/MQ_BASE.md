---
title: base
date: 2022-10-02 18:50:29
categories:
  - interview
  - MQ
tags:
  - 
---

参考：https://www.zhihu.com/question/54152397?sort=created

## 1.本质

将 MQ 掰开了揉碎了来看，都是「一发一存一消费」，再直白点就是一个「转发器」。

生产者先将消息投递一个叫做「队列」的容器中，然后再从这个容器中取出消息，最后再转发给消费者，仅此而已。

![img](https://i.loli.net/2021/10/20/SKUJXckV7d1mpbT.jpg)

## 2.模型演进

#### 基础队列模型

是一个严格意义上的队列（Queue）。消息按照什么顺序写进去，就按照什么顺序读出来。

允许多个生产者往同一个队列发送消息。但是，如果有多个消费者，实际上是竞争的关系，也就是一条消息只能被其中一个消费者接收到，读完即被删除。



#### ![img](https://i.loli.net/2021/10/20/bRMlYVQwaXT6m9y.jpg)

#### 发布订阅模型

如果需要将一份消息数据分发给多个消费者，并且每个消费者都要求收到全量的消息。很显然，队列模型无法满足这个需求。

一个可行的方案是：为每个消费者创建一个单独的队列，让生产者发送多份。这种做法比较笨，而且同一份数据会被复制多份，也很浪费空间。

为了解决这个问题，就演化出了另外一种消息模型：发布-订阅模型。

![img](https://i.loli.net/2021/10/20/gCszyAjRu7dX8bw.jpg)

#### 小结

简单而言就是单播和广播的区别。队列模型只会发给一个队列，有一个生产者和消费者。发布订阅模型，一个生产者可以有多个消费者。当发布-订阅模型中只有 1 个订阅者时，它和队列模型就一样了，因此在功能上是完全兼容队列模型的。

这也解释了为什么现代主流的 RocketMQ、Kafka 都是直接基于发布-订阅模型实现的？此外，RabbitMQ 中之所以有一个 Exchange 模块？其实也是为了解决消息的投递问题，可以变相实现发布-订阅模型。

消息模型，实际解决的是生产者和消费者的通信问题。对比 RPC ，很明显的变化在于一次 RPC 变成了现在的两次 RPC，将同步变成了异步。

![img](https://i.loli.net/2021/10/20/itfIbvSNLgrW68j.jpg)

## 3.应用场景

#### 常见的应用场景:

系统解耦，

异步通信，

流量削峰，

除此之外，还有延迟通知、最终一致性保证、顺序消息、流式处理等等。

先有了应用场景（问题），然后才有了消息模型，因为消息模型是解决方案的抽象。

####   特性与场景:

主要特性就是异步（请求拆分）和解耦（功能）。

举一个实际例子，比如说电商业务中最常见的「订单支付」场景：在订单支付成功后，需要更新订单状态、更新用户积分、通知商家有新订单、更新推荐系统中的用户画像等等。

![img](https://i.loli.net/2021/10/20/NYE78bvPM4oIB2u.jpg)	



引入 MQ 后，订单支付现在只需要关注它最重要的流程：更新订单状态即可。其他不重要的事情全部交给 MQ 来通知。这便是 MQ 解决的最核心的问题：系统解耦。改造前订单系统依赖 3 个外部系统，改造后仅仅依赖 MQ，而且后续业务再扩展（比如：营销系统打算针对支付用户奖励优惠券），也不涉及订单系统的修改，从而保证了核心流程的稳定性，降低了维护成本。

这个改造还带来了另外一个好处：因为 MQ 的引入，更新用户积分、通知商家、更新用户画像这些步骤全部变成了异步执行，能减少订单支付的整体耗时，提升订单系统的吞吐量。这便是 MQ 的另一个典型应用场景：

异步通信。

## 4.如何设计一个 MQ？

### - 雏形

简单而言，一发一存一消费，就是 MQ 最核心的功能需求。另外，从技术维度来看 MQ 的通信模型，可以理解成：两次 RPC + 消息转储。

有了这些理解，只要有一定的编程基础，不用 1 个小时就能写出一个 MQ 雏形：

1、直接利用成熟的 RPC 框架（Dubbo 或者 Thrift），实现两个接口：发消息和读消息。

2、消息放在本地内存中即可，数据结构可以用 JDK 自带的 ArrayBlockingQueue 。

### - 生产环境----实际场景思考

- 问题点

基础：发消息、存消息、消费消息（支持发布-订阅模式）。

高并发：

1、高并发场景下，如何保证收发消息的性能？

2、如何保证消息服务的高可用和高可靠？

3、如何保证服务是可以水平任意扩展的？

4、如何保证消息存储也是水平可扩展的？

5、各种元数据（比如集群中的各个节点、主题、消费关系等）如何管理，需不需要考虑数据的一致性？

- 整体思路 

先来看下整体架构，会涉及三类角色：

![img](https://i.loli.net/2021/10/20/zO6HgTbjMsB9IG5.jpg)

另外，将「一发一存一消费」这个核心流程进一步细化后，比较完整的数据流如下：

![img](https://i.loli.net/2021/10/20/yWsj2S9M6EGJbKL.jpg)

基于上面两个图，我们可以很快明确出 3 类角色的作用，分别如下：

1、Broker（服务端）：MQ 中最核心的部分，是 MQ 的服务端，核心逻辑几乎全在这里，它为生产者和消费者提供 RPC 接口，负责消息的存储、备份和删除，以及消费关系的维护等。

2、Producer（生产者）：MQ 的客户端之一，调用 Broker 提供的 RPC 接口发送消息。

3、Consumer（消费者）：MQ 的另外一个客户端，调用 Broker 提供的 RPC 接口接收消息，同时完成消费确认。

### - 详细设计

下面，再展开讨论下一些具体的技术难点和可行的解决方案。

**难点1：RPC 通信**

解决的是 Broker 与 Producer 以及 Consumer 之间的通信问题。如果不重复造轮子，直接利用成熟的 RPC 框架 Dubbo 或者 Thrift 实现即可，这样不需要考虑服务注册与发现、负载均衡、通信协议、序列化方式等一系列问题了。

当然，你也可以基于 Netty 来做底层通信，用 Zookeeper、Euraka 等来做注册中心，然后自定义一套新的通信协议（类似 Kafka），也可以基于 AMQP 这种标准化的 MQ 协议来做实现（类似 RabbitMQ）。对比直接用 RPC 框架，这种方案的定制化能力和优化空间更大。

**难点2：高可用设计**

高可用主要涉及两方面：Broker 服务的高可用、存储方案的高可用。可以拆开讨论。

Broker 服务的高可用，只需要保证 Broker 可水平扩展进行集群部署即可，进一步通过服务自动注册与发现、负载均衡、超时重试机制、发送和消费消息时的 ack 机制来保证。

存储方案的高可用有两个思路：1）参考 Kafka 的分区 + 多副本模式，但是需要考虑分布式场景下数据复制和一致性方案（类似 Zab、Raft等协议），并实现自动故障转移；2）还可以用主流的 DB、分布式文件系统、带持久化能力的 KV 系统，它们都有自己的高可用方案。

**难点3：存储设计**

消息的存储方案是 MQ 的核心部分，可靠性保证已经在高可用设计中谈过了，可靠性要求不高的话直接用内存或者分布式缓存也可以。这里重点说一下存储的高性能如何保证？这个问题的决定因素在于存储结构的设计。

目前主流的方案是：追加写日志文件（数据部分） + 索引文件的方式（很多主流的开源 MQ 都是这种方式），索引设计上可以考虑稠密索引或者稀疏索引，查找消息可以利用跳转表、二份查找等，还可以通过操作系统的页缓存、零拷贝等技术来提升磁盘文件的读写性能。

如果不追求很高的性能，也可以考虑现成的分布式文件系统、KV 存储或者数据库方案。

**难点4：消费关系管理**

为了支持发布-订阅的广播模式，Broker 需要知道每个主题都有哪些 Consumer 订阅了，基于这个关系进行消息投递。

由于 Broker 是集群部署的，所以消费关系通常维护在公共存储上，可以基于 Zookeeper、Apollo 等配置中心来管理以及进行变更通知。

**难点5：高性能设计**

存储的高性能前面已经谈过了，当然还可以从其他方面进一步优化性能。

比如 Reactor 网络 IO 模型、业务线程池的设计、生产端的批量发送、Broker 端的异步刷盘、消费端的批量拉取等等。

**小结**

再总结下，要回答好：如何设计一个 MQ？

1、需要从功能性需求（收发消息）和非功能性需求（高性能、高可用、高扩展等）两方面入手。

2、功能性需求不是重点，能覆盖 MQ 最基础的功能即可，至于延时消息、事务消息、重试队列等高级特性只是锦上添花的东西。

3、最核心的是：能结合功能性需求，理清楚整体的数据流，然后顺着这个思路去考虑非功能性的诉求如何满足，这才是技术难点所在。

# 常见队列

- RabbitMQ
- ActiveMQ

- RockMQ
- Kafka

- ZeroMQ
- Disque
