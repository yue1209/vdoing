---
title: SQL优化
date: 2021-10-15 13:42:48
permalink: /pages/df077d/
categories:
  - interview
tags:
  - 
---

参考链接

[爆肝，52条SQL语句，性能优化，干货必收藏 ！](https://mp.weixin.qq.com/s/R3i6BgHP6yvRLXAxFYsdmA)

[SQL 优化万能公式：5 大步骤 + 10 个案例](https://mp.weixin.qq.com/s/_zi661XsJXql68YL8N93Lw)

[TOC]

## 1.为什么进行优化

​		在应用开发的早期，数据量少，开发人员开发功能时更重视功能上的实现，随着生产数据的增长，很多SQL语句开始暴露出性能问题，对生产的影响也越来越大，有时可能这些有问题的SQL就是整个系统性能的瓶颈。查询慢的原因一般有，数据库连接池大小、服务器配置、未命中索引、返回数据太多、未释放锁等等。

## 2.确定需要优化的sql（慢sql）

### 1.监控

#### 1>mysql慢日志

​		默认情况下，MySQL没有开启慢查询日志。需要手动打开，如果不是调优需要的话，不建议开启，因为开启会带来一定的性能影响，慢查询日志支持将日志记录写入文件。

- 临时配置

  > -- 开启慢查询日志，只对当前数据库生效，并且重启数据库后失效
  > set global slow_query_log = 1;
  >
  > -- 查看慢查询日志是否开启
  > show variables like '%slow_query_log%';
  >
  > -- 设置阈值
  > set long_query_time = 3;
  >
  > -- 查看慢查询日志的阈值，单位是秒，默认10s
  > show variables like '%long_query_time%';
  >
  > -- 查询当前慢查询的数量  打开日志文件可以看到完整的sql
  > show global status like '%Slow_queries%';

- 永久配置

  > [mysqld]
  > slow_query_log=1
  > slow_query_log_file=/var/lib/mysql/atguigu-slow.log
  > long_query_time=3
  > log_output=FILE

- 慢日志分析工具mysqldumpslow

  > 可以将相同的慢SQL归类，并统计出相同的SQL执行的次数，每次执行耗时多久、总耗时，每次返回的行数、总行数，以及客户端连接信息等。
  >
  > - -s 表示按何种方式排序。
  > - c 访问次数。
  > - l 锁定时间。
  > - r 返回记录。
  > - t 查询时间。
  > - al 平均锁定时间。
  > - ar 平均返回记录数。
  > - at 平均查询时间。
  > - -t 返回前面多少条数据。
  > - -g 后面搭配一个正则匹配模式，大小写不敏感。
  >
  > ---------------------------------------------------------------------------------------------------------------------------------------
  >
  > -- 得到返回记录集最多的10 个SQL
  > mysqldumpslow -s r -t 10 /var/lib/mysql/atguigu-slow.log
  >
  > -- 得到访问次数最多的10 个SQL
  > mysqldumpslow -s c -t 10 /var/lib/mysql/atguigu-slow.log
  >
  > -- 得到按照时间排序的前10 条里面含有左连接的查询语句
  > mysqldumpslow -s t -t 10 -g "left join" /var/lib/mysql/atguigu-slow.log
  >
  > -- 另外建议在使用这些命令时结合| 和more 使用，否则有可能出现爆屏情况
  > mysqldumpslow -s r -t 10 /var/lib/mysql/atguigu-slow.log | more

#### 2>Druid监控

> 

#### 3>NPM监控

skywalking、听云以及一些其他监控服务

### 2.Explain 执行计划分析

​	explain会展示sql执行的相关信息，包括 表的加载顺序、sql的查询类型、匹配或使用到的索引、匹配到的数据行等等。其中需要重点关注的内容是type(索引使用类型)、rows（匹配行数）、filtered（）、extra。

- **type**   索引使用，效率依次降低

| 显示类型     | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| ALL          | 全表扫描                                                     |
| index        | 索引全扫描                                                   |
| range        | 索引范围扫描，常用语<,<=,>=,between,in等操作                 |
| ref          | 使用非唯一索引扫描或唯一索引前缀扫描，返回单条记录，常出现在关联查询中 |
| eq_ref       | 类似ref，区别在于使用的是唯一索引，使用主键的关联查询        |
| const/system | 单条记录，系统会把匹配行中的其他列作为常数处理，如主键或唯一索引查询 |
| null         | 不访问任何表或索引，直接返回结果                             |

- **Extra**

- Using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。
- Using temporary：使用了临时表保存中间结果，性能特别差，需要重点优化
- Using index：表示相应的 select 操作中使用了覆盖索引（Coveing Index）,避免访问了表的数据行，效率不错！如果同时出现 using where，意味着无法直接通过索引查找来查询到符合条件的数据。
- Using index condition：MySQL5.6之后新增的ICP，using index condtion就是使用了ICP（索引下推），在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据。

### 3.show profile 分析

了解SQL执行的线程的状态及消耗的时间。
默认是关闭的，开启语句“set profiling = 1;”

```
SHOW PROFILES ;
SHOW PROFILE FOR QUERY  #{id};
```

### 4.trace优化器分析

trace分析优化器如何选择执行计划，通过trace文件能够进一步了解为什么优化器选择A执行计划而不选择B执行计划。

```
-- 打开trace，设置格式为JSON，设置trace的缓存大小，避免因为容量大小而不能显示完整的跟踪过程。
set optimizer_trace="enabled=on",end_markers_in_JSON=on,optimizer_trace_max_mem_size=1000000;

-- 执行想做trace的SQL语句,然后查看跟踪记录
select * from information_schema.optimizer_trace;
```

## 3.具体措施

### 1.避免返回大量数据，避免回表查询和全表扫描

#### 1>尽量避免深度分页

当偏移量最大的时候，查询效率就会越低，因为Mysql并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。

- 方案一，返回上次最大查询记录（偏移量），这样可以跳过偏移量，效率提升不少。
- 方案二使用order by+索引，也是可以提高查询效率的。
- 方案三采用延迟关联的方式进行处理，减少SQL回表，但是要记得索引需要完全覆盖才有效果，
- 方案三的话，建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。

> 例：
>
> KEY `idx_a_b_c` (`a`, `b`, `c`)
>
> select * from _t where a = 1 and b = 2 order by c desc limit 10000, 10;
>
> 
>
> SELECT
> t1.*
> FROM
> _t t1,
> ( SELECT id FROM _t WHERE a = 1 AND b = 2 ORDER BY c DESC LIMIT 10000, 10 ) t2
> WHERE
> t1.id = t2.id;

#### 2>查询SQL尽量不要使用select *，而是select具体字段。查询语句一定要加条件限定。

- 只取需要的字段，节省资源、减少网络开销。
- select * 进行查询时，很可能就不会使用到覆盖索引了，就会造成回表查询。
- 加条件限定避免返回不必要的数据，节省开销。

#### 3>查询结果确定只要一条，建议用limit 1，防止全表扫描

加上limit 1后,只要找到了对应的一条记录,就不会继续向下扫描了,效率将会大大提高。但如果字段是唯一索引的话，有没有limit ，性能的差别并不大。

#### 4>慎用distinct关键字

当查询很多字段时，如果使用distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较，过滤的过程会占用系统资源，cpu时间。

#### 5>为了提高group by 语句的效率，可以在执行到该语句前，把不需要的记录过滤掉。



### 2.避免操作大批量的数据

#### 1>如果修改/删除语句设计数据过多时，尽量分批操作

同时修改或删除过多数据，会造成cpu利用率过高，从而影响别人对数据库的访问。可能会有lock wait timeout exceed的错误，甚至会影响主从同步的效率。

#### 2>连表查询尽量不要超过五个表，阿里的代码规范

- 连表越多，编译的时间和开销也就越大。
- 把连接表拆开成较小的几个执行，可读性更高。
- 如果一定需要连接很多表才能得到数据，那么意味着糟糕的设计了。

#### 3>连表查询尽量使用内连接

- 如果inner join是等值连接，或许返回的行数比较少，所以性能相对会好一点。
- 同理，使用了左连接，左边表数据结果尽量小，条件尽量放到左边处理，意味着返回的行数可能比较少。

### 3.索引

#### 1>避免隐式转换，会导致索引失效

隐式转换相当于在索引上做运算，会让索引失效。所以查询时数据类型要与字段类型保持一致。比如字段是varchar但是用了数字去匹配。因为不加单引号时，是字符串跟数字的比较，它们类型不匹配，MySQL会做隐式的类型转换，把它们转换为浮点数再做比较。

#### 2>最左匹配原则

从左向右匹配，如果索引是联合索引，那么查询条件的顺序要和索引中的字段顺序一致。

#### 3>in和order by

in在MySQL底层是通过`n*m`的方式去搜索，类似union，但是效率比union高。在进行cost代价计算时（`代价 = 元组数 * IO平均值`），是通过将in包含的数值，一条条去查询获取元组数的，因此这个计算过程会比较的慢，所以MySQL设置了个临界值(`eq_range_index_dive_limit`)，5.6之后超过这个临界值后该列的cost就不参与计算了。

因此会导致执行计划选择不准确。默认是200，即in条件超过了200个数据，会导致in的代价计算存在问题，可能会导致Mysql选择的索引不准确。

> 例:
>
> KEY `idx_shopid_status_created` (`shop_id`, `order_status`, `created_at`)
>
> 
>
> SELECT
> *
> FROM
> _order
> WHERE
> shop_id = 1
> AND order_status IN ( 1, 2, 3 )
> ORDER BY
> created_at DESC
> LIMIT 10
>
> 可以(`order_status`, `created_at`)互换前后顺序，并且调整SQL为延迟关联。

#### 4>避免在索引字段上进行计算、null值比较、内置函数

在索引上，避免使用NOT、!=、<>、!<、!>、NOT EXISTS、NOT IN、NOT LIKE等都会是索引失效

#### 5>避免在差异性不大的字段上建立索引，比如性别、删除标记等

如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%左右），优化器会选择通过聚集索引来查找数据。

#### 6>asc和desc混用,会导致索引失效

#### 7>尽量避免or的使用,会导致索引失效

#### 8>优化like语句

like模糊匹配%在前面不会走索引，放后面会走索引。对于这种强制全模糊匹配，有以下几种方式优化，

LOCATE函数，LOCATE（'substr',str,pos）,返回 substr 在 str 中第一次出现的位置，如果 substr 在 str 中不存在，返回值为 0 。存在则返回位置。

POSITION函数，可以看做是locate的别名，功能跟locate一样。

INSTR(`str`,'substr')，同上。

FIND_IN_SET(str1,str2)，返回str2中str1所在的位置索引，其中str2必须以","分割开。

mysql的全文索引，需要注意的是全文检索的对象是一个单词，被检索的词需要用非文本隔开的。比如在"abcd,efg,hijklmn"中检索"hi"，那么全文检索也没有用，如果你检索efg，那么可以使用全文检索。

再有一点需要说明的是无论建立哪种索引，MYSQL内建函数: FIND_IN_SET, POSITION，LOCATE都不能使用索引

#### 9>删除冗余和重复索引

重复的索引需要维护，并且优化器在优化查询的时候也需要逐个地进行考虑，这样会影响性能。

反例：

```
  KEY `idx_userId` (`userId`)
  KEY `idx_userId_age` (`userId`,`age`)
```

正例:

```
//删除userId索引，因为组合索引（A，B）相当于创建了（A）和（A，B）索引
  KEY `idx_userId_age` (`userId`,`age`)
```

#### 10>一般情况下，索引不要超过5个

索引虽然提高了查询的效率，但是也降低了插入和更新的效率。insert或update时有可能会重建索引，所以建索引需要慎重考虑。

#### 11>在where和order by涉及的列上建立索引，尽量避免全表扫描。

### --------------------------

### exist & in的合理利用

假设表A表示某企业的员工表，表B表示部门表，查询所有部门的所有员工，很容易有以下SQL:

```
select * from A where deptId in (select deptId from B);
```

这样写等价于：

> 先查询部门表B
>
> select deptId from B
>
> 再由部门deptId，查询A的员工
>
> select * from A where A.deptId = B.deptId

可以抽象成这样的一个循环：

```
   List<> resultSet ;
    for(int i=0;i<B.length;i++) {
          for(int j=0;j<A.length;j++) {
          if(A[i].id==B[j].id) {
             resultSet.add(A[i]);
             break;
          }
       }
    }
```

显然，除了使用in，我们也可以用exists实现一样的查询功能，如下：

```
select * from A where exists (select 1 from B where A.deptId = B.deptId);
```

因为exists查询的理解就是，先执行主查询，获得数据后，再放到子查询中做条件验证，根据验证结果（true或者false），来决定主查询的数据结果是否得意保留。

那么，这样写就等价于：

> select * from A,先从A表做循环
>
> select * from B where A.deptId = B.deptId,再从B表做循环.

同理，可以抽象成这样一个循环：

```
   List<> resultSet ;
    for(int i=0;i<A.length;i++) {
          for(int j=0;j<B.length;j++) {
          if(A[i].deptId==B[j].deptId) {
             resultSet.add(A[i]);
             break;
          }
       }
    }
```

数据库最费劲的就是跟程序链接释放。假设链接了两次，每次做上百万次的数据集查询，查完就走，这样就只做了两次；相反建立了上百万次链接，申请链接释放反复重复，这样系统就受不了了。即mysql优化原则，就是小表驱动大表，小的数据集驱动大的数据集，从而让性能更优。

因此，我们要选择最外层循环小的，也就是，如果**B的数据量小于A，适合使用in，如果B的数据量大于A，即适合选择exist**。

### 尽量用 union all 替换 union

如果检索结果中不会有重复的记录，推荐union all 替换 union。

理由：

- 如果使用union，不管检索结果有没有重复，都会尝试进行合并，然后在输出最终结果前进行排序。如果已知检索结果没有重复记录，使用union all 代替union，这样会提高效率。



## SQL优化一：

1、查询语句中不要使用`*`；

2、尽量减少子查询，使用关联查询（left join, right join, inner join）代替；

3、减少使用IN或者NOT IN，使用exists,not exists或者关联查询语句代替；

4、对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差；

5、合理的增加冗余的字段（减少表的关联查询）；

6、增加中间表进行优化（这个主要是在统计报表的场景，后台开定时任务将数据先统计好，尽量不要在查询的时候去统计）；

7、建表的时候能使用数字类型的字段就使用数字类型（type,status…），数字类型的字段作为条件查询比字符串快。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了；

8、那些可以过滤掉最大数量记录的条件必须写在where字句的最末尾；

9、索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要；

10、尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些；

11、对查询进行优化，应尽量避免全表扫描，首先应考虑在where以及order by涉及的列上建立索引。

## SQL优化二：索引失效情况优化

1、应尽量避免在 where 字句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描；

2、应尽量避免在 where 字句中使用 != 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描；

3、应尽量避免在 where 字句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描；

4、应尽量避免在 where 字句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描；

5、最佳左前缀法则（带头索引不能死，中间索引不能断）：在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致；

6、使用like关键字模糊查询时，% 放在前面索引不起作用，只有“%”不在第一个位置，索引才会生效（like ‘%文’–索引不起作用）；

7、应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描，尽量用union或者union all代替(在确认没有重复数据或者不用剔除重复数据时，union all会更好)；

8、如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则索引将会失效。

9、不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描。

10、存储引擎不能使用索引中范围条件右边的列 ——范围之后索引失效。（< ,> between and,）

11、尽量使用覆盖索引（只访问索引的查询（索引和查询列一致）），减少select*。——按需取数据用多少取多少。



